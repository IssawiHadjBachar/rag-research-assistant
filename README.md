# ğŸ§  RAG-Powered Research Paper Assistant

An intelligent **Retrieval-Augmented Generation (RAG)** assistant that helps you **analyze and query research papers**.
You can **upload PDFs** or **search arXiv**, and the system will build a semantic knowledge base using **SentenceTransformers** and **ChromaDB**, then answer your questions using **Google Gemini 1.5** through **LiteLLM**.

---

## ğŸš€ Features

* âœ… Upload and process multiple PDFs
* âœ… Search and summarize academic papers from **arXiv**
* âœ… Semantic text chunking and embedding via **SentenceTransformers**
* âœ… Persistent vector database using **ChromaDB**
* âœ… Context-aware question answering powered by **Gemini 1.5**
* âœ… Easy-to-use web interface built with **Streamlit**

---

## ğŸ—‚ï¸ Project Structure

```
ğŸ“¦ rag-research-assistant
 â”£ ğŸ“œ main.py                 # Main Streamlit application
 â”£ ğŸ“œ tools.py                # Utility functions for PDF processing, embeddings, and search
 â”£ ğŸ“œ requirements.txt        # Python dependencies
 â”£ ğŸ“œ .env                    # API keys 
 â”— ğŸ“‚ chroma_db               # Local persistent ChromaDB folder
```

---

## ğŸ§° Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/IssawiHadjBachar/rag-research-assistant.git
cd rag-research-assistant
```

---

### 2ï¸âƒ£ Create and Activate a Virtual Environment

#### On macOS/Linux:

```bash
python3 -m venv venv
source venv/bin/activate
```

#### On Windows:

```bash
python -m venv venv
venv\Scripts\activate
```

---

### 3ï¸âƒ£ Install Dependencies

Ensure you have **Python 3.10+** installed, then run:

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Set Up Environment Variables

Create a `.env` file in the root directory with the following content:

```
GEMINI_API_KEY=""
```

**Where to get the key:**

* [Google AI Studio](https://aistudio.google.com/api-keys)

---

## âš™ï¸ How It Works

1ï¸âƒ£ **PDF / arXiv Input** â†’ Extracts text from uploaded PDFs or fetches papers from arXiv.

2ï¸âƒ£ **Text Chunking** â†’ Uses `RecursiveCharacterTextSplitter` to create semantically meaningful chunks.

3ï¸âƒ£ **Embedding Generation** â†’ Each chunk is converted into a vector using `all-MiniLM-L6-v2` (SentenceTransformers).

4ï¸âƒ£ **Vector Storage** â†’ Embeddings are saved into a persistent ChromaDB collection (`knowledge_base`).

5ï¸âƒ£ **Query** â†’ User asks a question. The query is embedded and matched to the most relevant text chunks.

6ï¸âƒ£ **Response Generation** â†’ The top results are passed as context to Gemini 1.5 to generate a structured and relevant answer.

---

## ğŸ§ª Usage

Run the app with Streamlit:

```bash
streamlit run main.py
```

